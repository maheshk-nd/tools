{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d4e4974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4439d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv2_load(image_path):\n",
    "    im = cv2.imread(image_path).astype(np.float32)\n",
    "    assert im is not None, f'Image Not Found {image_path}'\n",
    "    h0, w0 = im.shape[:2] # 1080, 1920 \n",
    "    r = 640 / max(h0, w0)  # ratio # 640 / 1920\n",
    "    interp = cv2.INTER_LINEAR # if (r > 1) else cv2.INTER_AREA\n",
    "    im = cv2.resize(im, (int(w0 * r), int(h0 * r)), interpolation=interp)\n",
    "    img, ratio, pad = letterbox(im, [384, 640], auto=False, scaleup=False)\n",
    "    img = img.transpose((2, 0, 1))[::-1]\n",
    "    img = np.ascontiguousarray(img)\n",
    "    img = img / 255.0\n",
    "    return img[None, :]\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleFill=False, scaleup=True, stride=32):\n",
    "    # Resize and pad image while meeting stride-multiple constraints\n",
    "    shape = im.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    ratio = r, r  # width, height ratios\n",
    "    new_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "    if auto:  # minimum rectangle\n",
    "        dw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "    elif scaleFill:  # stretch\n",
    "        dw, dh = 0.0, 0.0\n",
    "        new_unpad = (new_shape[1], new_shape[0])\n",
    "        ratio = new_shape[1] / shape[1], new_shape[0] / shape[0]  # width, height ratios\n",
    "\n",
    "    dw /= 2  # divide padding into 2 sides\n",
    "    dh /= 2\n",
    "\n",
    "    if shape[::-1] != new_unpad:  # resize\n",
    "        im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "    left, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "    im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "    return im, ratio, (dw, dh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1072f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_onnx_session(modelpath):\n",
    "    options = None\n",
    "    # # create and run session\n",
    "    session = onnxruntime.InferenceSession(modelpath, sess_options=options, providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"])\n",
    "    return session\n",
    "\n",
    "def run_onnx_session(session, img):\n",
    "    ort_inputs = {session.get_inputs()[0].name: img}\n",
    "\n",
    "    prediction = session.run(None, ort_inputs)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "344642c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:115: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "onnx_session_a = create_onnx_session(\"/Users/maheshkumar/Downloads/onnxmodel\")\n",
    "# onnx_session_b = create_onnx_session(\"../MergedModels/tycho_yolo_v6.1.0/onnxmodel\")\n",
    "onnx_session_b = create_onnx_session(\"/Users/maheshkumar/Downloads/onnxmodel\")\n",
    "# onnx_session_b = create_onnx_session('../FeatureHeadsModels/tycho_yolo_v6.0.2_beta_v3/mhmodel_NO_NMS_2023_07_11_08_13.onnx')\n",
    "# onnx_session_b = create_onnx_session('../MergedModels/tycho_yolo_v6.0.3/mhmodel_NO_NMS_2023_08_28_19_45_v5_1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7bab5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# onnx_session_b = create_onnx_session(\"../MergedModels/tycho_yolo_v6.1.0/onnxmodel\")\n",
    "# onnx_session_b = create_onnx_session('../FeatureHeadsModels/tycho_yolo_v6.0.2_beta_v3/mhmodel_NO_NMS_2023_07_11_08_13.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c1da86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = \"/Users/maheshkumar/Desktop/test_image.png\"\n",
    "\n",
    "im = cv2_load(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1e24243",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_prediction_a = run_onnx_session(onnx_session_a, im)\n",
    "onnx_prediction_b = run_onnx_session(onnx_session_b, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3dff93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 (1, 2) (1, 2)\n",
      "3 (1, 2) (1, 2)\n",
      "4 (1, 4) (1, 4)\n",
      "5 (1, 5) (1, 5)\n",
      "6 (1, 7) (1, 7)\n",
      "7 (1, 6) (1, 6)\n",
      "8 (1, 6) (1, 6)\n",
      "9 (1, 6) (1, 6)\n",
      "10 (1, 4) (1, 4)\n"
     ]
    }
   ],
   "source": [
    "for i in range(11):\n",
    "    # print(i, onnx_prediction_a[i].shape, onnx_prediction_b[i].shape)\n",
    "    if i > 1:\n",
    "        print(i, onnx_prediction_a[i].shape, onnx_prediction_b[i].shape)\n",
    "        np.testing.assert_almost_equal(onnx_prediction_a[i], onnx_prediction_b[i], decimal=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "877a2860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pred = onnx_prediction_b[12][0]\n",
    "cv2.imwrite(\"/Users/maheshkumar/code/segmentation_output2.png\",onnx_pred.astype('uint8')*255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99df3960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1269)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63af4dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

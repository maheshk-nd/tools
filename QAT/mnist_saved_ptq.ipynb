{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "\n",
    "from pytorch_quantization import nn as quant_nn\n",
    "from pytorch_quantization import calib\n",
    "from pytorch_quantization.tensor_quant import QuantDescriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226799/1387068913.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"mnist_cnn.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "state_dict = torch.load(\"mnist_cnn.pth\")\n",
    "model.load_state_dict(state_dict)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_quantization import quant_modules\n",
    "quant_modules.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_desc_input = QuantDescriptor(calib_method='histogram')\n",
    "quant_nn.QuantConv2d.set_default_quant_desc_input(quant_desc_input)\n",
    "quant_nn.QuantLinear.set_default_quant_desc_input(quant_desc_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_226799/523587435.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"mnist_cnn.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): QuantConv2d(\n",
       "    1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "    (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "  )\n",
       "  (conv2): QuantConv2d(\n",
       "    32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
       "    (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "    (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): QuantLinear(\n",
       "    in_features=3136, out_features=128, bias=True\n",
       "    (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "    (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "  )\n",
       "  (fc2): QuantLinear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (_input_quantizer): TensorQuantizer(8bit fake per-tensor amax=dynamic calibrator=HistogramCalibrator scale=1.0 quant)\n",
       "    (_weight_quantizer): TensorQuantizer(8bit fake axis=0 amax=dynamic calibrator=MaxCalibrator scale=1.0 quant)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_qat = CNN().to(device)\n",
    "\n",
    "state_dict = torch.load(\"mnist_cnn.pth\")\n",
    "model_qat.load_state_dict(state_dict)\n",
    "model_qat.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:06<00:00,  3.33s/it]\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0203 11:58:25.454816 139764016534784 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0203 11:58:25.455624 139764016534784 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0203 11:58:25.456214 139764016534784 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0203 11:58:25.456840 139764016534784 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0203 11:58:25.457414 139764016534784 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0203 11:58:25.458050 139764016534784 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0203 11:58:25.458580 139764016534784 tensor_quantizer.py:174] Disable HistogramCalibrator\n",
      "W0203 11:58:25.459197 139764016534784 tensor_quantizer.py:174] Disable MaxCalibrator\n",
      "W0203 11:58:25.463215 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0203 11:58:25.463669 139764016534784 tensor_quantizer.py:239] Call .cuda() if running on GPU after loading calibrated amax.\n",
      "W0203 11:58:25.464229 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([32, 1, 1, 1]).\n",
      "W0203 11:58:25.465682 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0203 11:58:25.466220 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([64, 1, 1, 1]).\n",
      "W0203 11:58:25.467229 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0203 11:58:25.467765 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([128, 1]).\n",
      "W0203 11:58:25.471077 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([]).\n",
      "W0203 11:58:25.472745 139764016534784 tensor_quantizer.py:238] Load calibrated amax, shape=torch.Size([10, 1]).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=2.8201 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "conv1._weight_quantizer                 : TensorQuantizer(8bit fake axis=0 amax=[0.3197, 0.5787](32) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "conv2._input_quantizer                  : TensorQuantizer(8bit fake per-tensor amax=4.4838 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "conv2._weight_quantizer                 : TensorQuantizer(8bit fake axis=0 amax=[0.1594, 0.4042](64) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "fc1._input_quantizer                    : TensorQuantizer(8bit fake per-tensor amax=8.7644 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "fc1._weight_quantizer                   : TensorQuantizer(8bit fake axis=0 amax=[0.0230, 0.2383](128) calibrator=MaxCalibrator scale=1.0 quant)\n",
      "fc2._input_quantizer                    : TensorQuantizer(8bit fake per-tensor amax=44.7928 calibrator=HistogramCalibrator scale=1.0 quant)\n",
      "fc2._weight_quantizer                   : TensorQuantizer(8bit fake axis=0 amax=[0.1774, 0.2029](10) calibrator=MaxCalibrator scale=1.0 quant)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "def collect_stats(model, data_loader, num_batches):\n",
    "    \"\"\"Feed data to the network and collect statistic\"\"\"\n",
    "\n",
    "    # Enable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.disable_quant()\n",
    "                module.enable_calib()\n",
    "            else:\n",
    "                module.disable()\n",
    "\n",
    "    for i, (image, _) in tqdm(enumerate(data_loader), total=num_batches):\n",
    "        model(image.cuda())\n",
    "        if i >= num_batches:\n",
    "            break\n",
    "\n",
    "    # Disable calibrators\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                module.enable_quant()\n",
    "                module.disable_calib()\n",
    "            else:\n",
    "                module.enable()\n",
    "\n",
    "def compute_amax(model, **kwargs):\n",
    "    # Load calib result\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, quant_nn.TensorQuantizer):\n",
    "            if module._calibrator is not None:\n",
    "                if isinstance(module._calibrator, calib.MaxCalibrator):\n",
    "                    module.load_calib_amax()\n",
    "                else:\n",
    "                    module.load_calib_amax(**kwargs)\n",
    "            print(F\"{name:40}: {module}\")\n",
    "    model.cuda()\n",
    "\n",
    "# It is a bit slow since we collect histograms on CPU\n",
    "with torch.no_grad():\n",
    "    collect_stats(model_qat, train_loader, num_batches=2)\n",
    "    compute_amax(model_qat, method=\"percentile\", percentile=99.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0229, Accuracy: 99.34%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "def evaluate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            total_loss += criterion(outputs, labels).item()\n",
    "            correct += (outputs.argmax(1) == labels).sum().item()\n",
    "\n",
    "    print(f\"Test Loss: {total_loss / len(test_loader):.4f}, Accuracy: {correct / len(test_loader.dataset) * 100:.2f}%\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    evaluate(model_qat, device, test_loader, criterion)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model_qat.state_dict(), \"mnist_quant-calibrated.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%actual_input_1 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cuda:0),\n",
      "      %conv1.weight : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv1.bias : Float(32, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.weight : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cuda:0),\n",
      "      %conv2.bias : Float(64, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.weight : Float(128, 3136, strides=[3136, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc1.bias : Float(128, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.weight : Float(10, 128, strides=[128, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc2.bias : Float(10, strides=[1], requires_grad=1, device=cuda:0)):\n",
      "  %/conv1/_input_quantizer/Constant_output_0 : Char(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/conv1/_input_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv1/_input_quantizer/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.0222056}, onnx_name=\"/conv1/_input_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv1/_input_quantizer/QuantizeLinear_output_0 : Char(1, 1, 28, 28, strides=[784, 784, 28, 1], device=cpu) = onnx::QuantizeLinear[onnx_name=\"/conv1/_input_quantizer/QuantizeLinear\"](%actual_input_1, %/conv1/_input_quantizer/Constant_1_output_0, %/conv1/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv1/_input_quantizer/DequantizeLinear_output_0 : Float(1, 1, 28, 28, strides=[784, 784, 28, 1], requires_grad=0, device=cuda:0) = onnx::DequantizeLinear[onnx_name=\"/conv1/_input_quantizer/DequantizeLinear\"](%/conv1/_input_quantizer/QuantizeLinear_output_0, %/conv1/_input_quantizer/Constant_1_output_0, %/conv1/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv1/_weight_quantizer/Constant_output_0 : Float(32, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/conv1/_weight_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv1/_weight_quantizer/Constant_1_output_0 : Char(32, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/conv1/_weight_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv1/_weight_quantizer/QuantizeLinear_output_0 : Char(32, 1, 3, 3, strides=[9, 9, 3, 1], device=cpu) = onnx::QuantizeLinear[axis=0, onnx_name=\"/conv1/_weight_quantizer/QuantizeLinear\"](%conv1.weight, %/conv1/_weight_quantizer/Constant_output_0, %/conv1/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv1/_weight_quantizer/DequantizeLinear_output_0 : Float(32, 1, 3, 3, strides=[9, 9, 3, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[axis=0, onnx_name=\"/conv1/_weight_quantizer/DequantizeLinear\"](%/conv1/_weight_quantizer/QuantizeLinear_output_0, %/conv1/_weight_quantizer/Constant_output_0, %/conv1/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv1/Conv_output_0 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/conv1/Conv\"](%/conv1/_input_quantizer/DequantizeLinear_output_0, %/conv1/_weight_quantizer/DequantizeLinear_output_0, %conv1.bias), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv1 # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %/relu/Relu_output_0 : Float(1, 32, 28, 28, strides=[25088, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/relu/Relu\"](%/conv1/Conv_output_0), scope: __main__.CNN::/torch.nn.modules.activation.ReLU::relu # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/pool/MaxPool_output_0 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/pool/MaxPool\"](%/relu/Relu_output_0), scope: __main__.CNN::/torch.nn.modules.pooling.MaxPool2d::pool # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/conv2/_input_quantizer/Constant_output_0 : Char(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/conv2/_input_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv2/_input_quantizer/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.0353055}, onnx_name=\"/conv2/_input_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv2/_input_quantizer/QuantizeLinear_output_0 : Char(1, 32, 14, 14, strides=[6272, 196, 14, 1], device=cpu) = onnx::QuantizeLinear[onnx_name=\"/conv2/_input_quantizer/QuantizeLinear\"](%/pool/MaxPool_output_0, %/conv2/_input_quantizer/Constant_1_output_0, %/conv2/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv2/_input_quantizer/DequantizeLinear_output_0 : Float(1, 32, 14, 14, strides=[6272, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[onnx_name=\"/conv2/_input_quantizer/DequantizeLinear\"](%/conv2/_input_quantizer/QuantizeLinear_output_0, %/conv2/_input_quantizer/Constant_1_output_0, %/conv2/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/conv2/_weight_quantizer/Constant_output_0 : Float(64, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/conv2/_weight_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv2/_weight_quantizer/Constant_1_output_0 : Char(64, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/conv2/_weight_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv2/_weight_quantizer/QuantizeLinear_output_0 : Char(64, 32, 3, 3, strides=[288, 9, 3, 1], device=cpu) = onnx::QuantizeLinear[axis=0, onnx_name=\"/conv2/_weight_quantizer/QuantizeLinear\"](%conv2.weight, %/conv2/_weight_quantizer/Constant_output_0, %/conv2/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv2/_weight_quantizer/DequantizeLinear_output_0 : Float(64, 32, 3, 3, strides=[288, 9, 3, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[axis=0, onnx_name=\"/conv2/_weight_quantizer/DequantizeLinear\"](%/conv2/_weight_quantizer/QuantizeLinear_output_0, %/conv2/_weight_quantizer/Constant_output_0, %/conv2/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/conv2/Conv_output_0 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=0, device=cuda:0) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/conv2/Conv\"](%/conv2/_input_quantizer/DequantizeLinear_output_0, %/conv2/_weight_quantizer/DequantizeLinear_output_0, %conv2.bias), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_conv.QuantConv2d::conv2 # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/quant_conv.py:130:0\n",
      "  %/relu_1/Relu_output_0 : Float(1, 64, 14, 14, strides=[12544, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/relu_1/Relu\"](%/conv2/Conv_output_0), scope: __main__.CNN::/torch.nn.modules.activation.ReLU::relu # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/pool_1/MaxPool_output_0 : Float(1, 64, 7, 7, strides=[3136, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[ceil_mode=0, dilations=[1, 1], kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/pool_1/MaxPool\"](%/relu_1/Relu_output_0), scope: __main__.CNN::/torch.nn.modules.pooling.MaxPool2d::pool # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/torch/nn/functional.py:830:0\n",
      "  %/Constant_output_0 : Long(2, strides=[1], device=cpu) = onnx::Constant[value=   -1  3136 [ CPULongType{2} ], onnx_name=\"/Constant\"](), scope: __main__.CNN:: # /tmp/ipykernel_226799/1026670601.py:16:0\n",
      "  %/Reshape_output_0 : Float(1, 3136, strides=[3136, 1], requires_grad=1, device=cuda:0) = onnx::Reshape[onnx_name=\"/Reshape\"](%/pool_1/MaxPool_output_0, %/Constant_output_0), scope: __main__.CNN:: # /tmp/ipykernel_226799/1026670601.py:16:0\n",
      "  %/fc1/_input_quantizer/Constant_output_0 : Char(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/fc1/_input_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc1/_input_quantizer/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.0690109}, onnx_name=\"/fc1/_input_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc1/_input_quantizer/QuantizeLinear_output_0 : Char(1, 3136, strides=[3136, 1], device=cpu) = onnx::QuantizeLinear[onnx_name=\"/fc1/_input_quantizer/QuantizeLinear\"](%/Reshape_output_0, %/fc1/_input_quantizer/Constant_1_output_0, %/fc1/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc1/_input_quantizer/DequantizeLinear_output_0 : Float(1, 3136, strides=[3136, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[onnx_name=\"/fc1/_input_quantizer/DequantizeLinear\"](%/fc1/_input_quantizer/QuantizeLinear_output_0, %/fc1/_input_quantizer/Constant_1_output_0, %/fc1/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc1/_weight_quantizer/Constant_output_0 : Float(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/fc1/_weight_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc1/_weight_quantizer/Constant_1_output_0 : Char(128, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=<Tensor>, onnx_name=\"/fc1/_weight_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc1/_weight_quantizer/QuantizeLinear_output_0 : Char(128, 3136, strides=[3136, 1], device=cpu) = onnx::QuantizeLinear[axis=0, onnx_name=\"/fc1/_weight_quantizer/QuantizeLinear\"](%fc1.weight, %/fc1/_weight_quantizer/Constant_output_0, %/fc1/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc1/_weight_quantizer/DequantizeLinear_output_0 : Float(128, 3136, strides=[3136, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[axis=0, onnx_name=\"/fc1/_weight_quantizer/DequantizeLinear\"](%/fc1/_weight_quantizer/QuantizeLinear_output_0, %/fc1/_weight_quantizer/Constant_output_0, %/fc1/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc1/Gemm_output_0 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc1/Gemm\"](%/fc1/_input_quantizer/DequantizeLinear_output_0, %/fc1/_weight_quantizer/DequantizeLinear_output_0, %fc1.bias), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc1 # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/quant_linear.py:73:0\n",
      "  %/relu_2/Relu_output_0 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cuda:0) = onnx::Relu[onnx_name=\"/relu_2/Relu\"](%/fc1/Gemm_output_0), scope: __main__.CNN::/torch.nn.modules.activation.ReLU::relu # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/torch/nn/functional.py:1704:0\n",
      "  %/fc2/_input_quantizer/Constant_output_0 : Char(requires_grad=0, device=cpu) = onnx::Constant[value={0}, onnx_name=\"/fc2/_input_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc2/_input_quantizer/Constant_1_output_0 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.3527}, onnx_name=\"/fc2/_input_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc2/_input_quantizer/QuantizeLinear_output_0 : Char(1, 128, strides=[128, 1], device=cpu) = onnx::QuantizeLinear[onnx_name=\"/fc2/_input_quantizer/QuantizeLinear\"](%/relu_2/Relu_output_0, %/fc2/_input_quantizer/Constant_1_output_0, %/fc2/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc2/_input_quantizer/DequantizeLinear_output_0 : Float(1, 128, strides=[128, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[onnx_name=\"/fc2/_input_quantizer/DequantizeLinear\"](%/fc2/_input_quantizer/QuantizeLinear_output_0, %/fc2/_input_quantizer/Constant_1_output_0, %/fc2/_input_quantizer/Constant_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_input_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:285:0\n",
      "  %/fc2/_weight_quantizer/Constant_output_0 : Float(10, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value=0.001 *  1.5581  1.5980  1.5914  1.4553  1.3967  1.4701  1.4982  1.5879  1.4620  1.5141 [ CUDAFloatType{10} ], onnx_name=\"/fc2/_weight_quantizer/Constant\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc2/_weight_quantizer/Constant_1_output_0 : Char(10, strides=[1], requires_grad=0, device=cuda:0) = onnx::Constant[value= 0  0  0  0  0  0  0  0  0  0 [ CUDACharType{10} ], onnx_name=\"/fc2/_weight_quantizer/Constant_1\"](), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc2/_weight_quantizer/QuantizeLinear_output_0 : Char(10, 128, strides=[128, 1], device=cpu) = onnx::QuantizeLinear[axis=0, onnx_name=\"/fc2/_weight_quantizer/QuantizeLinear\"](%fc2.weight, %/fc2/_weight_quantizer/Constant_output_0, %/fc2/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %/fc2/_weight_quantizer/DequantizeLinear_output_0 : Float(10, 128, strides=[128, 1], requires_grad=1, device=cuda:0) = onnx::DequantizeLinear[axis=0, onnx_name=\"/fc2/_weight_quantizer/DequantizeLinear\"](%/fc2/_weight_quantizer/QuantizeLinear_output_0, %/fc2/_weight_quantizer/Constant_output_0, %/fc2/_weight_quantizer/Constant_1_output_0), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2/pytorch_quantization.nn.modules.tensor_quantizer.TensorQuantizer::_weight_quantizer # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/tensor_quantizer.py:294:0\n",
      "  %output1 : Float(1, 10, strides=[10, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc2/Gemm\"](%/fc2/_input_quantizer/DequantizeLinear_output_0, %/fc2/_weight_quantizer/DequantizeLinear_output_0, %fc2.bias), scope: __main__.CNN::/pytorch_quantization.nn.modules.quant_linear.QuantLinear::fc2 # /home/ubuntu/miniconda3/envs/conda_venv_pytrt/lib/python3.12/site-packages/pytorch_quantization/nn/modules/quant_linear.py:73:0\n",
      "  return (%output1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytorch_quantization\n",
    "dummy_input = torch.randn(1, 1, 28, 28, device='cuda')\n",
    "\n",
    "input_names = [ \"actual_input_1\" ]\n",
    "output_names = [ \"output1\" ]\n",
    "\n",
    "#with pytorch_quantization.enable_onnx_export():#\n",
    "quant_nn.TensorQuantizer.use_fb_fake_quant = True\n",
    "# enable_onnx_checker needs to be disabled. See notes below.\n",
    "torch.onnx.export(\n",
    "    model_qat, dummy_input, \"mnist_quant.onnx\", verbose=True, opset_version=13, enable_onnx_checker=False, input_names = [ \"actual_input_1\" ], output_names = [ \"output1\" ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_venv_pytrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
